> 💡 **한 줄 요약**
>
> 트래픽 급증 시 대처 방법인 스케일 아웃의 필수적 개념으로, 여러 대의 서버에 서버의 요청을 분산하는 방법이며 시스템의 안정성을 높인다.

### 1. 🤔 왜 사용하는가

> **트래칙 급증 시 대처 방법**
>
> - 스케일 업 : 서버 자체의 성능을 높이는 방법
>   - RAM이나 CPU를 업그레이드 하는 것
> - 스케일 아웃 : 서버를 추가해 성능을 향상시키는 방법
>   - 처리할 일을 여러 대의 서버로 나누어 분산 처리하는 방법
>     → 로드 밸런싱

- 여러 대의 서버에 서버의 요청을 분산하는 방법이다.
- 클라이언트의 요청이 여러 서버로 골고루 나누어져 서버의 부하를 줄일 수 있다.
- 로드 밸런서 : 트래픽을 골고루 나누어 주는 모듈
  - 들어오는 요청을 여러 서버에 효율적으로 배분하는 기계나 소프트웨어

### 2. 💡 무엇인지 아는가(특징)

- **로드 밸런싱 알고리즘**

  - 로드 밸런서가 서로 다른 클라이언트 요청 각각에 가장 적합한 서버 결정위해 따르는 규칙
  - 종류
    - 정적 로드 밸런싱 : 고정된 규칙 따르며 현재 서버 상태와 무관
      - 라운드 로빈 방식 : 요청을 서버 사이에서 차례대로 분배하는 방법
      - 가중 기반 라운드 로빈 방식
      - IP 해시 방식
    - 동적 로드 밸런싱 : 트래픽 배포 전 서버의 현재 상태 검사
      - 최소 연결 방법 : 서버이 현재 부하와 연결 상태를 바탕으로 요청 보내는 방식
      - 가중치 기반 최소 연결 방법
      - 최소 응답 시간 방법
      - 리소스 기반 방법

- **작동 방식**

  - 하드웨어 로드 밸런서 : 온프레미스에 설치하는 물리적 기기
    - 물리적으로 서버를 묶어 안정성과 보안 제공, 비용이 많이 듦
  - 소프트웨어 로드 밸런서 : 개인 소유 서버에 설치하거나 관리형 클라우드 서비스로 이용할 수 있는 애플리케이션
    - HAProxy, 엔진 X, 아파치 웹 서버를 포함해 로직 구현하고 트래픽 분산시키는 효율적이고 저렴항 방법

  1. 클라이언트 요청을 실시간으로 중재, 요청 잘 처리할 수 있는 서버 결정
  2. 서버에 과부하 걸리지 않도록 온프레미스/서버팜/클라우드 데이터 센터에 호스팅된 사용할 수 있는 서버 수에 따라 요청을 라우팅
  3. 할당된 서버는 요청 받으면 로드 밸런서 통해 클라이언트에 응답
     1. 로드 밸런서가 클라이언트의 IP 주소 선택한 서버의 IP 주소와 일치시켜 서버-클라이언트 연결함
     2. 클라이언트와 서버는 세션 완료될 때까지 통신 및 요청된 작업 수행 가능
  4. 네트워크 트래픽이 급증하는 경우, 로드 밸런서가 많은 서버를 온라인 상태로 전환 가능
     1. 잠잠해지면 밸런서가 사용할 수 있는 서버 풀 줄일 수 있음
     2. 이전 사용자 요청이 저장되는 캐시 서버로 트래픽 라우팅해 네트워크 캐싱 지원 가능

- **로드 밸런서 유형**
  - 네트워크 로드 밸런서
  - 애플리케이션 로드 밸런서
  - 가상 로드 밸런서
  - 글로벌 서버 로드 밸런서

### 3. ✅ 장점

- **가용성**
  - 서버 문제를 자동으로 감지하고 클라이언트 트래픽을 사용 가능한 서버로 리디렉션해 시스템의 내결함성을 높임
    - 애플리케이션 가동 중지 없이 서버 유지 관리 및 업그레이드 실행
    - 백업 사이트에 자동 재해 복구 제공
    - 상태 확인 수행, 가동 중지 유발할 수 있는 문제 방지
- **확장성**
  - 여러 서버 간에 네트워크 트래픽을 지능적으로 전달 가능
    - 한 서버에서 트래픽 병목 현상 방지
    - 필요한 경우 다른 서버 추가하거나 제거할 수 있도록 트래픽 예측
- **보안**
  - 또 다른 보안 계층 추가할 수 있는 보안 기능 내장
    - 트래픽 모니터링 및 악성 콘텐츠 차단
    - 공격 트래픽을 여러 백엔드 서버로 자동으로 리디렉션해 영향 최소화
    - 추가 보안을 위해 네트워크 방화벽 그룹을 통해 트래픽 라우팅
- **성능**
  - 응답 시간을 늘리고 네트워크 지연 시간을 줄여 성능 향상시킴
    - 서버 간에 로드 균등 배포해 성능 향상
    - 클라이언트 요청을 지리적으로 더 가까운 서버로 리디렉션해 지연 시간 단축
    - 물리적 및 가상 컴퓨팅 리소스의 신뢰성 및 성능 보장
